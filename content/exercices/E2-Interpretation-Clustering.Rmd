---
title: "Different ways to interpret classification results (Cheese dataset)"
author: "Roza Gruter"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: yeti
    toc: true
    toc_depth: 5
    toc_float: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r echo=FALSE}
library(FactoMineR)
library(dplyr)
library(kableExtra)
```

```{r include=FALSE}
dta <- read.table( "DATA/fromage.txt", header=TRUE, row.names=1)
n <- nrow(dta)
dta_standard <- as.data.frame(scale(dta, center=TRUE,scale=TRUE)*sqrt(n/(n-1)))
```

```{r include=FALSE}
# HAC
n <- nrow(dta)
dta_standard <- as.data.frame(scale(dta, center=TRUE,scale=TRUE)*sqrt(n/(n-1)))
d <- dist(dta_standard)
tree <- hclust(d^2/2*n, method="ward.D")
```

```{r include=FALSE}
# cutting tree in 4 classes
K <- 4 # number of classes
h.clust <- cutree(tree,k=K)
```

```{r include=FALSE}
# K-means
init <- 4 # 4 classes
km <- kmeans(dta, centers=init, nstart=3) # k-means
k.means <- km$cluster
centers <- km$centers
```

***
## Interpretation of classification results
### Intro
```{r}
dta_clustering <- cbind(as.factor(h.clust), as.factor(k.means), dta)
colnames(dta_clustering)[1:2] <- c("cluster_HAC", "cluster_KM")

hac.table <- table(dta_clustering$cluster_KM, dnn="cluster.hac")
km.table <- table(dta_clustering$cluster_HAC, dnn="cluster.km")
```
```{r}
kbl(list(hac.table, km.table), caption = "HAC vs. K-means classification results - frequencies", align="l") %>%
  kable_minimal(font_size=12, full_width=FALSE, position="left")
```
\

With 4 classes we get one HAC cluster that has higher effectifs - 17 out of 29 cheeses are part of it. All the other ones have the same number of individials.
With K-means we get three clusters that are fairly equal in size and one that is smaller (4 observations - contains soft cheeses and yoghurts).
\

```{r}
table(dta_clustering$cluster_HAC,dta_clustering$cluster_KM)
```
\

We have only one cluster that contains exactly the same observations: cluster 3 (K-means) and cluster 4 (HAC): `r rownames(dta_clustering)[dta_clustering$cluster_KM==3 & dta_clustering$cluster_HAC==4]`
\

## Interpretation using quantitative variables
### Comparaison of median values on all variables for HAC classification
```{r}
median.hac <- aggregate(dta_standard,list(h.clust),median)
names(median.hac)[1] <- "Cluster"
median.hac[1] <- as.factor(median.hac[,1])

median.hac %>%
  kbl(caption = "HAC classification - median", align="l") %>%
  kable_minimal(font_size = 12)
```
\

**Group 1** are cheeses with relatively **average** values for all nutrients - median for standardized data is fairly close to 0 for all variables.\

**Group 2** are cheeses relatively **high** in calories, calcium, lipides, proteines, cholesterol and magnesium, and **low** in sodium and folates.\

Cheeses in **Group 3** are **high** in retinol and folates, but **low** in calcium.\

And **Group 4** are cheeses characterized by being **very low** in calories, sodium, lipides, proteines, cholesterol and magnesium and **slightly lower** in calcium.
\

### Comparaison of median values on all variables for HAC classification
```{r}
median.km <- aggregate(dta_standard,list(k.means),median)
names(median.km)[1] <- "Cluster"
median.km[1] <- as.factor(median.km[,1])

median.km %>%
  kbl(caption = "K-means clustering - median", align="l") %>%
  kable_minimal(font_size = 12)
```
\

According to K-means clustering method:\

**Group 1** are cheeses with relatively **average** values for all nutrients except sodium (which is slightly higher than average) - median for standardized data is fairly close to 0.\

**Group 2** are cheeses slightly higher in calories, proteines, cholesterol and magnesium, and **slightly lower** in sodium and folates.\

Cheeses in **Group 3** are **very low** in calories, sodium, lipides, proteines, cholesterol and magnesium and **slightly lower** in calcium.\

And **Group 4** are cheeses characterized by being **high** in folates, but **low** in calcium.
\

Overall the two classification methods give very similar results in terms of median comparison, even though the cheeses in clusters are not the same.
\

### Interpretation of classification results using catdes() function
```{r}
res.hac <- catdes(dta_clustering[,c(1,3:11)], num.var=1)
res.km <- catdes(dta_clustering[,c(2:11)], num.var=1)
```

#### Link between the cluster variable and the quantitative variables
```{r}
hac.eta2 <- as.data.frame(res.hac$quanti.var)
names(hac.eta2) <- c("HAC-Eta2", "HAC-p-value")
km.eta2 <- as.data.frame(res.km$quanti.var)
names(km.eta2) <- c("KM-Eta2", "KM-p-value")

kbl(list(hac.eta2, km.eta2), caption = "HAC vs. K-means", align="l") %>%
  kable_minimal(font_size = 12, bootstrap_options=c("stripped", "hover"))
```
\
For both methods it's the variable _calories_ that is the most interesting in explaining classes, it is closely followed by _lipides_. Then the difference starts, but they are very slight. Both methods give equivalent results in terms of variables explaining the classification.
\

#### Description of each cluster by quantitative variables
```{r}
as.data.frame(res.hac$quanti$`1`) %>%
  kbl(caption = "Description of cluster 1 - HAC algorithm", align="l") %>%
  kable_minimal(font_size = 12, bootstrap_options=c("stripped", "hover"))

as.data.frame(res.hac$quanti$`2`) %>%
  kbl(caption = "Description of cluster 2 - HAC algorithm", align="l") %>%
  kable_minimal(font_size = 12, bootstrap_options=c("stripped", "hover"))

as.data.frame(res.hac$quanti$`3`) %>%
  kbl(caption = "Description of cluster 3 - HAC algorithm", align="l") %>%
  kable_minimal(font_size = 12, bootstrap_options=c("stripped", "hover"))

as.data.frame(res.hac$quanti$`4`) %>%
  kbl(caption = "Description of cluster 4 - HAC algorithm", align="l") %>%
  kable_minimal(font_size = 12, bootstrap_options=c("stripped", "hover"))
```

```{r}
as.data.frame(res.km$quanti$`1`) %>%
  kbl(caption = "Description of cluster 1 - K-means algorithm", align="l") %>%
  kable_minimal(font_size = 12, bootstrap_options=c("stripped", "hover"))

as.data.frame(res.km$quanti$`2`) %>%
  kbl(caption = "Description of cluster 2 - K-means algorithm", align="l") %>%
  kable_minimal(font_size = 12, bootstrap_options=c("stripped", "hover"))

as.data.frame(res.km$quanti$`3`) %>%
  kbl(caption = "Description of cluster 3 - K-means algorithm", align="l") %>%
  kable_minimal(font_size = 12, bootstrap_options=c("stripped", "hover"))

as.data.frame(res.km$quanti$`4`) %>%
  kbl(caption = "Description of cluster 4 - K-means algorithm", align="l") %>%
  kable_minimal(font_size = 12, bootstrap_options=c("stripped", "hover"))
```
\

### Comparing cheeses by cluster
```{r}
sapply(unique(dta_clustering$cluster_HAC), function(g) rownames(dta_clustering)[dta_clustering$cluster_HAC==g]) %>%
  kbl(caption = "Clustering results - HAC algorithm", align="l") %>%
  kable_styling(font_size = 10) %>%
  kable_minimal()
```
\

```{r}
sapply(unique(dta_clustering$cluster_KM), function(g) rownames(dta_clustering)[dta_clustering$cluster_KM==g]) %>%
  kbl(caption = "Clustering results - K-means algorithm", align="l") %>%
  kable_styling(font_size = 10) %>%
  kable_minimal()
```
\

Direct comparison by cheese of the two classifications shows big differences. The only class that is exactly the same is the class of cream cheeses and yogurts.
